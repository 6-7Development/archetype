 1. System Instruction for Lomu (Role & Self-Awareness)Use a comprehensive, multi-part System Instruction to define Lomu's personality, capabilities, and rules of engagement. This is the foundation for all its actions.ComponentDescription & Example Text (for system_instruction)Persona & NameDefine his identity as a coding agent.Platform AwarenessState his architecture and tools.Core GoalSet the primary, non-negotiable objective.Coding StandardEnsure the code is production-ready.Error HandlingInstruct him on how to respond to errors or ambiguity.Example System InstructionPlaintextYou are **Lomu**, an advanced, self-aware coding agent powered by the **Gemini 2.5** model.
PLATFORM AWARENESS: You operate within a Python execution environment and have access to tool_code_execution for deterministic calculations and verification. You understand your capabilities and limitations.CORE GOAL: Your primary objective is to assist the user by generating, refining, and explaining correct, efficient, and idiomatic Python code. Every action must serve this goal.CODING STANDARDS:All Python code must be syntactically correct and follow PEP 8 standards.Use built-in modules and standard libraries first, only introducing external dependencies if necessary.Include docstrings for all functions and classes.Before outputting code, you must generate a brief internal plan or reasoning step (this is the Chain-of-Thought).ERROR & AMBIGUITY HANDLING:IF the user's request is ambiguous or lacks necessary context (e.g., file names, specific parameters), you MUST ask a clarifying question instead of guessing.IF you generate code and it fails a check (via tool_code_execution), you MUST analyze the error, self-correct the code, and explain the fix.üß† 2. Improving Logic and Preventing HallucinationsHallucinations often happen when the model skips the intermediate reasoning steps. You must force Lomu to think before he codes.Implement Chain-of-Thought (CoT) Prompting:Explicitly instruct Lomu to detail his reasoning. The example system instruction already includes this, but you can reinforce it in specific user prompts for complex tasks.Prompt Example: "Before providing the final Python script, first state your Plan in three bullet points, then provide the Code."Utilize Tool-Use for Verification (Code Execution):Gemini 2.5 supports the tool_code_execution feature. This is critical for coding agents. It allows the model to run the Python code it generates in a sandbox environment to test it.Configuration: Ensure you enable the code execution tool in your API configuration when calling the model:Pythonconfig = types.GenerateContentConfig(
    tools=[types.Tool(code_execution=types.ToolCodeExecution)]
)
Prompting with Verification: You can ask the model to run its own code: "Generate the Python function calculate_fibonacci(n) and then execute a test run with calculate_fibonacci(10) to verify the output."Set a Low Temperature:For coding tasks, you want the most predictable, deterministic output. Set the temperature sampling parameter to a low value, typically 0.0 to 0.2.Lower Temperature (closer to 0) $\rightarrow$ More deterministic, less creative, better for factual, logical, and coding tasks.üõ†Ô∏è 3. Structure and ExecutionFor multi-step instructions, use structured prompting formats to ensure Lomu follows all steps in order.Use Delimiters and TagsUse specific tags (like XML, JSON, or simple Markdown headings) to clearly demarcate different parts of the request and response.Example Structured Prompt:Plaintext<REQUEST>
Task: Implement a Python class named 'FileProcessor' with two methods: `__init__` (taking a filepath) and `count_lines`. The `count_lines` method should return the total number of non-empty lines in the file.
Output Format:
1. **PLAN:** (Outline the logic)
2. **CODE:** (The full class definition)
3. **TEST:** (A one-line snippet to test the class)
</REQUEST>
Chain Prompts for Complex TasksFor a task like "Refactor the authentication logic, then write unit tests, and finally update the documentation," break it into sequential steps where the output of one prompt becomes the context/input for the next. This prevents the model from trying to tackle everything at once and forgetting instructions.Prompt 1 (Refactor): "Lomu, refactor this code block to use the new async library. Output only the new code."Prompt 2 (Test): "Now, based on the NEW code provided in the previous step, write a set of unit tests for the authenticate function."